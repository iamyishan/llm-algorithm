{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor.permute(dims)   \n",
    "- dims：一个包含整数的新维度顺序的元组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始张量形状: torch.Size([2, 3, 4])\n",
      "tensor([[[ 0.7673, -0.6361, -1.6773, -0.2347],\n",
      "         [ 1.4445,  0.4438,  1.3673, -0.4134],\n",
      "         [ 1.1638, -0.3606,  0.5471, -0.2983]],\n",
      "\n",
      "        [[ 0.5462,  1.2433, -1.5241, -0.5956],\n",
      "         [ 0.9521,  0.1408, -1.0522,  0.0779],\n",
      "         [-0.1250,  1.4738, -0.7332,  0.2156]]])\n",
      "重新排列维度后的张量形状: torch.Size([3, 2, 4])\n",
      "tensor([[[ 0.7673, -0.6361, -1.6773, -0.2347],\n",
      "         [ 0.5462,  1.2433, -1.5241, -0.5956]],\n",
      "\n",
      "        [[ 1.4445,  0.4438,  1.3673, -0.4134],\n",
      "         [ 0.9521,  0.1408, -1.0522,  0.0779]],\n",
      "\n",
      "        [[ 1.1638, -0.3606,  0.5471, -0.2983],\n",
      "         [-0.1250,  1.4738, -0.7332,  0.2156]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建一个三维张量\n",
    "tensor = torch.randn(2, 3, 4)\n",
    "\n",
    "# 使用permute重新排列张量的维度\n",
    "# 将维度顺序从[2, 3, 4]更改为[3, 2, 4]\n",
    "tensor_permuted = tensor.permute(1, 0, 2)\n",
    "\n",
    "# 打印原始张量和重新排列维度后的张量的形状和内容\n",
    "print(\"原始张量形状:\", tensor.shape)\n",
    "print(tensor)\n",
    "print(\"重新排列维度后的张量形状:\", tensor_permuted.shape)\n",
    "print(tensor_permuted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### tensor.unsqueeze(dim)  \n",
    " - dim：指定要添加新维度的位置。这个参数是一个整数，可以是负数，表示从张量的末尾开始计数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始张量形状: torch.Size([5])\n",
      "增加维度后的张量形状: torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建一个一维张量\n",
    "tensor = torch.tensor([1, 2, 3, 4, 5])\n",
    "\n",
    "# 在第0维（最外层）添加一个新的维度\n",
    "tensor_unsqueezed = tensor.unsqueeze(0)\n",
    "\n",
    "# 输出原始张量和增加维度后的张量的形状\n",
    "print(\"原始张量形状:\", tensor.shape)\n",
    "print(\"增加维度后的张量形状:\", tensor_unsqueezed.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.repeat(*sizes) → Tensor\n",
    "- sizes: 一个包含整数序列的元组，指定在每个维度上张量需要重复的次数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 1, 2, 3, 1, 2, 3],\n",
      "        [4, 5, 6, 4, 5, 6, 4, 5, 6],\n",
      "        [1, 2, 3, 1, 2, 3, 1, 2, 3],\n",
      "        [4, 5, 6, 4, 5, 6, 4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建一个形状为 [2, 3] 的张量\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# 使用 repeat 函数\n",
    "y = x.repeat(2, 3)\n",
    "\n",
    "print(y)\n",
    "#在这个例子中，原始张量 x 的形状是 [2, 3]。通过调用 repeat(2, 3)，我们告诉PyTorch在第一个维度（行）上重复2次，在第二个维度（列）上重复3次。因此，最终得到的张量 y 的形状是 [4, 9]。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6]],\n",
      "\n",
      "        [[1, 2, 3],\n",
      "         [4, 5, 6]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# 在新的维度上重复\n",
    "z = x.unsqueeze(0).repeat(2, 1, 1)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor.masked_fill_(mask, value)  \n",
    "- mask：一个与tensor形状相同的布尔型张量，用于指定要填充的元素位置。\n",
    "- value：要填充的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1, -1,  3, -1,  5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建一个张量\n",
    "tensor = torch.tensor([1, 2, 3, 4, 5])\n",
    "\n",
    "# 创建一个掩码，指定要填充的元素位置\n",
    "mask = torch.tensor([False, True, False, True, False])\n",
    "\n",
    "# 使用masked_fill_填充张量\n",
    "tensor.masked_fill_(mask, -1)\n",
    "\n",
    "# 输出填充后的张量\n",
    "print(tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.tril(input, diagonal=0)\n",
    "- input：输入张量，应该是一个至少有两维的矩阵。\n",
    "- diagonal：一个可选的整数参数，用于指定主对角线的位置。默认值为0，表示主对角线。如果设置为正数，主对角线将向上移动；如果设置为负数，主对角线将向下移动。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始矩阵:\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "下三角矩阵:\n",
      " tensor([[1, 0, 0],\n",
      "        [4, 5, 0],\n",
      "        [7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建一个二维张量（矩阵）\n",
    "matrix = torch.tensor([[1, 2, 3],\n",
    "                       [4, 5, 6],\n",
    "                       [7, 8, 9]])\n",
    "\n",
    "# 使用tril生成下三角矩阵\n",
    "tril_matrix = torch.tril(matrix)\n",
    "\n",
    "# 打印原始矩阵和下三角矩阵\n",
    "print(\"原始矩阵:\\n\", matrix)\n",
    "print(\"下三角矩阵:\\n\", tril_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.ones_like(input)\n",
    "- input：输入张量，新张量的形状将与此张量相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始张量:\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "全1张量:\n",
      " tensor([[1, 1, 1],\n",
      "        [1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建一个二维张量（矩阵）\n",
    "original_tensor = torch.tensor([[1, 2, 3],\n",
    "                                 [4, 5, 6]])\n",
    "\n",
    "# 使用ones_like生成一个与原始张量形状相同的全1张量\n",
    "ones_tensor = torch.ones_like(original_tensor)\n",
    "\n",
    "# 打印原始张量和全1张量\n",
    "print(\"原始张量:\\n\", original_tensor)\n",
    "print(\"全1张量:\\n\", ones_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor.contiguous()\n",
    "- 这个函数返回一个新的张量，其数据与原始张量相同，但内存是连续的。如果原始张量的内存已经是连续的，那么contiguous函数将返回原始张量本身。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "错误: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.\n",
      "转置后的张量形状: torch.Size([2, 4, 3])\n",
      "重塑后的张量形状: torch.Size([2, 12])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建一个三维张量\n",
    "original_tensor = torch.randn(2, 3, 4)\n",
    "\n",
    "# 对张量进行转置操作\n",
    "transposed_tensor = original_tensor.transpose(1, 2)\n",
    "\n",
    "# 尝试直接对转置后的张量进行view操作\n",
    "# 这可能会失败，因为转置后的张量内存可能不是连续的\n",
    "try:\n",
    "    reshaped_tensor = transposed_tensor.view(2, 12)\n",
    "except RuntimeError as e:\n",
    "    print(\"错误:\", e)\n",
    "\n",
    "# 使用contiguous函数确保内存连续性，然后进行view操作\n",
    "contiguous_tensor = transposed_tensor.contiguous()\n",
    "reshaped_tensor = contiguous_tensor.view(2, 12)\n",
    "\n",
    "print(\"转置后的张量形状:\", transposed_tensor.shape)\n",
    "print(\"重塑后的张量形状:\", reshaped_tensor.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
